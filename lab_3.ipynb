{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bitarray import bitarray\n",
    "from collections import defaultdict\n",
    "from heapq import heappop, heappush\n",
    "from os import listdir\n",
    "from sys import getsizeof\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statyczne kodowanie Huffmana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zakodowany tekst posiada na początku informacje dotyczące kodowania:\n",
    "- 1 bajt przechowujący ilość nieważnych bitów dodanych do końca zakodowanego tekstu (dopełnienie ilości bitów do wielokrotności 8)\n",
    "- 2 bajty przechowujące wielkość zapisanego dalej kodowania\n",
    "- kodowanie każdej z liter, każde w postaci:  \n",
    "  - 1 bajt przechowujący literę (kodowanie utf-8)\n",
    "  - 1 bajt przechowujący wielkość kodowania\n",
    "  - kodowanie litery\n",
    "  \n",
    "  \n",
    "Następnie znajduje się zakodowany tekst.  \n",
    "Całość zapisywana jest w pliku binarnym."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_letters(text):\n",
    "    count = defaultdict(lambda: 0)\n",
    "    for l in text:\n",
    "        count[l] += 1\n",
    "    return count\n",
    "\n",
    "class Node():\n",
    "    def __init__(self, weight=None, children=None, label=None, code=None, parent=None, **kwargs):\n",
    "        self.weight = weight\n",
    "        self.children = children\n",
    "        self.label = label\n",
    "        self.code = code\n",
    "        self.parent = parent\n",
    "        if parent is not None:\n",
    "            self.parent = parent\n",
    "            if parent.children:\n",
    "                parent.children.append(self)\n",
    "            else:\n",
    "                parent.children = [self]\n",
    "        if children is not None:\n",
    "            for node in children:\n",
    "                node.parent = self\n",
    "        \n",
    "    def is_leaf(self):\n",
    "        return self.children is None\n",
    "    \n",
    "    def find_child(self, code):\n",
    "        if self.children is None:\n",
    "            return None\n",
    "        if self.children[0].code == int(code):\n",
    "            return self.children[0]\n",
    "        elif len(self.children) == 2:\n",
    "            return self.children[1]\n",
    "        return None\n",
    "    \n",
    "    def __ge__(self, other):\n",
    "        return self.weight >= other.weight\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return self.weight == other.weight\n",
    "    \n",
    "    def __gt__(self, other):\n",
    "        return self.weight > other.weight\n",
    "        \n",
    "def code(tree):\n",
    "    tree.children[0].code = 0\n",
    "    tree.children[1].code = 1\n",
    "    if not tree.children[0].is_leaf():\n",
    "        code(tree.children[0])\n",
    "    if not tree.children[1].is_leaf():\n",
    "        code(tree.children[1])\n",
    "\n",
    "def huffman(text):\n",
    "    count = count_letters(text)\n",
    "    trees = []\n",
    "    leafs = []\n",
    "    for l, weight in count.items():\n",
    "        node = Node(weight, label=l)\n",
    "        heappush(trees, node)\n",
    "        leafs.append(node)\n",
    "        \n",
    "    while len(trees) > 1:\n",
    "        t1 = heappop(trees)\n",
    "        t2 = heappop(trees)\n",
    "\n",
    "        parent = Node(children=[t1, t2],weight=t1.weight + t2.weight)\n",
    "        heappush(trees, parent)\n",
    "    code(trees[0])\n",
    "    return trees[0], leafs\n",
    "\n",
    "def get_code(leaf):\n",
    "    code = str(leaf.code)\n",
    "    parent = leaf.parent\n",
    "    while parent is not None and parent.code is not None:\n",
    "        code += str(parent.code)\n",
    "        parent = parent.parent\n",
    "    return code[::-1]\n",
    "    \n",
    "    \n",
    "def print_huffman(node, prefix=\"\"):\n",
    "    assert not node.is_leaf()\n",
    "    if node.children[0].is_leaf() and node.children[1].is_leaf():\n",
    "        leaf = node.children[0]\n",
    "        print(f\"{prefix}{leaf.code} -> #{leaf.weight} {leaf.label} {get_code(leaf)}\")\n",
    "        leaf = node.children[1]\n",
    "        print(f\"{prefix}{leaf.code} -> #{leaf.weight} {leaf.label} {get_code(leaf)}\")\n",
    "    elif node.children[0].is_leaf() or node.children[1].is_leaf():\n",
    "        if node.children[0].is_leaf():\n",
    "            leaf = node.children[0]\n",
    "            internal = node.children[1]\n",
    "        else:\n",
    "            leaf = node.children[1]\n",
    "            internal = node.children[0]\n",
    "        print(f\"{prefix}{leaf.code} -> #{leaf.weight} {leaf.label} {get_code(leaf)}\")\n",
    "        print(f\"{prefix}{internal.code} -> #{internal.weight}\")\n",
    "        print_huffman(internal, prefix=prefix+\" \")\n",
    "    else:\n",
    "        print(f\"{prefix}{node.children[0].code} -> #{node.children[0].weight}\")\n",
    "        print_huffman(node.children[0], prefix=prefix+\" \")\n",
    "        print(f\"{prefix}{node.children[0].code} -> #{node.children[1].weight}\")\n",
    "        print_huffman(node.children[1], prefix=prefix+\" \")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -> #5 a 0\n",
      "1 -> #6\n",
      " 0 -> #2\n",
      "  0 -> #1 c 100\n",
      "  1 -> #1 d 101\n",
      " 0 -> #4\n",
      "  0 -> #2 r 110\n",
      "  1 -> #2 b 111\n"
     ]
    }
   ],
   "source": [
    "node, leafs = huffman(\"abracadabra\")\n",
    "print_huffman(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(text, encoder, with_encoding=False):\n",
    "    encoded_text = bitarray()\n",
    "    if with_encoding:\n",
    "        for k, v in encoder.items():\n",
    "            encoded_text.frombytes(bytes(k, encoding=\"utf_8\"))\n",
    "            encoded_text.frombytes(len(v).to_bytes(1, 'big'))\n",
    "            encoded_text += bitarray(v)\n",
    "\n",
    "    encoded_text = bitarray((len(encoded_text)).to_bytes(3, \"big\")) + encoded_text\n",
    "    for l in text:\n",
    "        encoded_text += bitarray(encoder[l])\n",
    "    bits_added = encoded_text.fill()\n",
    "    encoded_text = bitarray(bits_added.to_bytes(2, \"big\")) + encoded_text\n",
    "    return encoded_text.tobytes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10kb.txt\n",
      "1MB.txt\n",
      "100kb.txt\n",
      "1kb.txt\n"
     ]
    }
   ],
   "source": [
    "texts = []\n",
    "text_dir = \"compression texts\"\n",
    "for filename in listdir(text_dir):\n",
    "    print(filename)\n",
    "    with open(text_dir + \"/\" + filename, \"r\") as file:\n",
    "        text = file.read()\n",
    "    texts.append((filename, text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10kb.txt\n",
      "compression coefficient = 0.4512085944494181\n",
      "1MB.txt\n",
      "compression coefficient = 0.4648634103072645\n",
      "100kb.txt\n",
      "compression coefficient = 0.464029495813433\n",
      "1kb.txt\n",
      "compression coefficient = 0.3638863428047663\n"
     ]
    }
   ],
   "source": [
    "def compress(text, with_encoding=True):\n",
    "    node, leafs = huffman(text)\n",
    "    encoder = {leaf.label: get_code(leaf) for leaf in leafs}\n",
    "    return encode(text, encoder, with_encoding=with_encoding)\n",
    "\n",
    "compressed_texts = []\n",
    "for filename, text in texts:\n",
    "    print(filename)\n",
    "    encoded_text = compress(text, with_encoding=True)\n",
    "    compressed_texts.append((filename, encoded_text))\n",
    "    filename = filename.split(\".\")[0]\n",
    "    with open(filename + \".compressed\", \"wb\") as file:\n",
    "        file.write(encoded_text)\n",
    "    print(f\"compression coefficient = {1 - getsizeof(encoded_text) / getsizeof(text)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_tree(text):\n",
    "    root = Node()\n",
    "    start = 0\n",
    "    end = 8\n",
    "    while end <= len(text):\n",
    "        letter = text[start:end].tobytes().decode(encoding='utf_8')\n",
    "        start += 8\n",
    "        end += 8\n",
    "        code_size = int.from_bytes(text[start:end].tobytes(), 'big')\n",
    "        start += 8\n",
    "        end = start + code_size\n",
    "        code = text[start:end]\n",
    "        start = end\n",
    "        end += 8\n",
    "        node = root\n",
    "       # print(letter, code_size, code)\n",
    "        for i, c in enumerate(code):\n",
    "            c = int(c)\n",
    "            child = node.find_child(c)\n",
    "            if child is None:\n",
    "                if code_size==i+1:\n",
    "                    node = Node(code=c, parent=node, label=letter)\n",
    "                else:\n",
    "                    node = Node(code=c, parent=node)\n",
    "            else:\n",
    "                node = child\n",
    "    return root\n",
    "\n",
    "def get_letter(text, tree, start):\n",
    "    n = start\n",
    "    node = tree\n",
    "    while not node.is_leaf():\n",
    "        node = node.find_child(int(text[n]))\n",
    "        n += 1\n",
    "    return node.label, n\n",
    "        \n",
    "            \n",
    "def decode(text):\n",
    "    encoded_text = bitarray()\n",
    "    encoded_text.frombytes(text)\n",
    "    fill = int.from_bytes(encoded_text[:8].tobytes(), 'big')\n",
    "    tree_size = int.from_bytes(encoded_text[8:24].tobytes(), 'big')\n",
    "    tree = decode_tree(encoded_text[24:24+tree_size])\n",
    "    encoded_text[:24+tree_size] = bitarray() # this part will not be needed again\n",
    "    encoded_text[-fill:] = bitarray()\n",
    "    decoded_text = []\n",
    "    i = 0\n",
    "    while len(encoded_text) > i:\n",
    "        letter, i = get_letter(encoded_text, tree, i)\n",
    "        decoded_text.append(letter)\n",
    "    return \"\".join(decoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sprawdzenie poprawności odkodowanego tekstu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10kb.txt\n",
      "1MB.txt\n",
      "100kb.txt\n",
      "1kb.txt\n"
     ]
    }
   ],
   "source": [
    "for filename, text in texts:\n",
    "    print(filename)\n",
    "    filename = filename.split(\".\")[0]\n",
    "    with open(filename + \".compressed\", \"rb\") as file:\n",
    "        encoded_text = file.read()\n",
    "    decoded_text = decode(encoded_text)\n",
    "    assert decoded_text == text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Porównanie czasu kodowania i dekodowania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "637 ms ± 89.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "for filename, text in texts:\n",
    "    compress(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.21 s ± 211 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "for filename, text in compressed_texts:\n",
    "    decode(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamiczne kodowanie Huffmana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zakodowany tekst posiada na początku informacje dotyczące kodowania:\n",
    "- 1 bajt przechowujący ilość nieważnych bitów dodanych do końca zakodowanego tekstu (dopełnienie ilości bitów do wielokrotności 8)\n",
    "- 1 bajt przechowujący wielkość alfabetu\n",
    "- alfabet (wszystkie litery występujące w tekście w kolejnośći ich pierwszego wystąpienia)\n",
    "  \n",
    "Następnie znajduje się zakodowany tekst.  \n",
    "Całość zapisywana jest w pliku binarnym."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaptiveNode(Node):\n",
    "    def __init__(self, idx, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.idx = idx\n",
    "        \n",
    "        \n",
    "class AdaptiveTree():\n",
    "    def __init__(self, first_letter, first_code=0):\n",
    "        self.root = AdaptiveNode(idx=0, weight=1)\n",
    "        node = AdaptiveNode(idx=1, label=first_letter, code=first_code, weight=1, parent=self.root)\n",
    "        zero_node = AdaptiveNode(idx=2, weight=0, code=(first_code+1)%2, parent=self.root)\n",
    "        self.nodes = [self.root, node, zero_node]\n",
    "        \n",
    "    def find_highest_sibling(self, node):\n",
    "        highest_idx = node.idx - 1\n",
    "        while highest_idx >= 0 and self.nodes[highest_idx].weight == node.weight:\n",
    "            highest_idx -= 1\n",
    "        return self.nodes[highest_idx+1]\n",
    "    \n",
    "    def swap(self, idx1, idx2):\n",
    "        node1 = self.nodes[idx1]\n",
    "        node2 = self.nodes[idx2]\n",
    "        parent1 = self.nodes[idx1].parent\n",
    "        parent2 = self.nodes[idx2].parent\n",
    "\n",
    "        if parent1:\n",
    "            if parent1.children[0] is node1:\n",
    "                parent1.children[0] = node2\n",
    "            else:\n",
    "                parent1.children[1] = node2\n",
    "        if parent2:\n",
    "            if parent2.children[0] is node2:\n",
    "                parent2.children[0] = node1\n",
    "            else:\n",
    "                parent2.children[1] = node1\n",
    "        node1.parent = parent2\n",
    "        node2.parent = parent1\n",
    "        node1.code, node2.code = node2.code, node1.code \n",
    "        self.nodes[idx1], self.nodes[idx2] = self.nodes[idx2], self.nodes[idx1]\n",
    "        node1.idx, node2.idx = node2.idx, node1.idx \n",
    "        \n",
    "        \n",
    "    def increment(self, node):\n",
    "        sibling = self.find_highest_sibling(node)\n",
    "        if sibling is not self.root and sibling is not node and sibling is not node.parent:\n",
    "            self.swap(sibling.idx, node.idx)\n",
    "        node.weight += 1\n",
    "        if node.parent is not None:\n",
    "            self.increment(node.parent)\n",
    "    \n",
    "    @staticmethod\n",
    "    def other_code(node):\n",
    "        return (node.code + 1) % 2\n",
    "    \n",
    "    def add_node(self, label):\n",
    "        zero_node = self.nodes[-1]\n",
    "        parent = zero_node.parent\n",
    "        assert parent is not None\n",
    "        \n",
    "        new_inner = AdaptiveNode(weight=0, code=zero_node.code, \n",
    "                                 idx=zero_node.idx)\n",
    "        new_inner.parent = zero_node.parent\n",
    "        leaf = AdaptiveNode(weight=1, label=label, code=self.other_code(zero_node), \n",
    "                    parent=new_inner, idx=zero_node.idx+1)\n",
    "        zero_node.idx += 2\n",
    "        zero_node.parent = new_inner\n",
    "        new_inner.children.append(zero_node)\n",
    "\n",
    "        if parent.children[0] == zero_node:\n",
    "            parent.children[0] = new_inner\n",
    "        else:\n",
    "            parent.children[1] = new_inner\n",
    "        self.nodes[new_inner.idx] = new_inner\n",
    "        self.nodes.append(leaf)\n",
    "        self.nodes.append(zero_node)\n",
    "        self.increment(new_inner)\n",
    "        return leaf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_leaf(leafs, label):\n",
    "    for leaf in leafs:\n",
    "        if leaf.label == label:\n",
    "            return leaf\n",
    "    return None\n",
    "\n",
    "def check_tree(node):\n",
    "    print(f\"check {node.label} | w={node.weight}\")\n",
    "    if node.is_leaf():\n",
    "        pass\n",
    "    else:\n",
    "        assert len(node.children) == 2\n",
    "        check_tree(node.children[0])\n",
    "        check_tree(node.children[1])\n",
    "\n",
    "def adaptive_huffman_encode(text):\n",
    "    alphabet = [text[0]]\n",
    "    tree = AdaptiveTree(text[0])\n",
    "    leafs = [tree.nodes[1]]\n",
    "    encoded = bitarray(get_code(leafs[0]))\n",
    "    for letter in text[1:]:\n",
    "        leaf = find_leaf(leafs, letter)\n",
    "\n",
    "        if leaf:\n",
    "            encoded += bitarray(get_code(leaf))\n",
    "         #   print(\"inc\", get_code(leaf)+' '+leaf.label)\n",
    "            tree.increment(leaf)\n",
    "        else:\n",
    "            alphabet.append(letter)\n",
    "            zero_node = tree.nodes[-1]\n",
    "            encoded += bitarray(get_code(zero_node))\n",
    "            \n",
    "            leaf = tree.add_node(letter)\n",
    "            leafs.append(leaf)\n",
    "            \n",
    "    bit_alphabet = bitarray()\n",
    "    bit_alphabet.frombytes(bytes(\"\".join(alphabet), encoding=\"utf_8\"))\n",
    "    alphabet_size = len(alphabet)\n",
    "    bit_size = bitarray((alphabet_size).to_bytes(2, \"big\"))\n",
    "    fill = encoded.fill()\n",
    "    bit_fill = bitarray((fill).to_bytes(2, \"big\"))\n",
    "    return (bit_fill + bit_size + bit_alphabet + encoded).tobytes()\n",
    "            \n",
    "abracadabra = adaptive_huffman_encode(\"abracadabra\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10kb.txt\n",
      "compression coefficient = 0.45797274445439173\n",
      "1MB.txt\n",
      "compression coefficient = 0.4649122457318835\n",
      "100kb.txt\n",
      "compression coefficient = 0.46464898782997943\n",
      "1kb.txt\n",
      "compression coefficient = 0.4207149404216315\n"
     ]
    }
   ],
   "source": [
    "compressed_texts = []\n",
    "for filename, text in texts:\n",
    "    print(filename)\n",
    "    encoded_text = adaptive_huffman_encode(text)\n",
    "    compressed_texts.append((filename, encoded_text))\n",
    "    filename = filename.split(\".\")[0]\n",
    "    with open(filename + \".compressed\", \"wb\") as file:\n",
    "        file.write(encoded_text)\n",
    "    print(f\"compression coefficient = {1 - getsizeof(encoded_text) / getsizeof(text)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abracadabra'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_node(text, node, start):\n",
    "    n = start\n",
    "    while not node.is_leaf():\n",
    "        node = node.find_child(int(text[n]))\n",
    "        n += 1\n",
    "    return node, n\n",
    "\n",
    "def adaptive_huffman_decode(encoded_text):\n",
    "    encoded = bitarray()\n",
    "    encoded.frombytes(encoded_text)\n",
    "    fill = int.from_bytes(encoded[:8].tobytes(), 'big')\n",
    "    alphabet_size = int.from_bytes(encoded[8:16].tobytes(), 'big')\n",
    "    alphabet = encoded[16:16+8*alphabet_size].tobytes().decode(\"utf_8\")\n",
    "    tree = AdaptiveTree(alphabet[0])\n",
    "    leafs = [tree.nodes[1]]\n",
    "    decoded = [alphabet[0]]\n",
    "    unused = 1\n",
    "    \n",
    "    start = 16 + 8 * alphabet_size + 1\n",
    "    while start < len(encoded) - fill:\n",
    "        leaf, start = get_node(encoded, tree.root, start)\n",
    "        if leaf.label:\n",
    "            decoded.append(leaf.label)\n",
    "            tree.increment(leaf)\n",
    "        else:\n",
    "            letter = alphabet[unused]\n",
    "            decoded.append(letter)\n",
    "            unused += 1\n",
    "            \n",
    "            zero_node = tree.nodes[-1]\n",
    "            leaf = tree.add_node(letter)\n",
    "            leafs.append(leaf)\n",
    "            \n",
    "    return \"\".join(decoded)\n",
    "\n",
    "adaptive_huffman_decode(abracadabra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sprawdzenie poprawności odkodowanego tekstu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10kb.txt\n",
      "1MB.txt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-0455646bb8e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".compressed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mencoded_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mdecoded_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madaptive_huffman_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mdecoded_text\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-1915fcaf7b5c>\u001b[0m in \u001b[0;36madaptive_huffman_decode\u001b[0;34m(encoded_text)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mleaf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mdecoded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleaf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mincrement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleaf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mletter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malphabet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0munused\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-23f17350d364>\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mincrement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-23f17350d364>\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mincrement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-23f17350d364>\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msibling\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msibling\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msibling\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msibling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mincrement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for filename, text in texts:\n",
    "    print(filename)\n",
    "    filename = filename.split(\".\")[0]\n",
    "    with open(filename + \".compressed\", \"rb\") as file:\n",
    "        encoded_text = file.read()\n",
    "    decoded_text = adaptive_huffman_decode(encoded_text)\n",
    "    assert decoded_text == text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Porównanie czasu kodowania i dekodowania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.31 s ± 497 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "for filename, text in texts:\n",
    "    adaptive_huffman_encode(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.53 s ± 558 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "for filename, text in [texts[1]]:\n",
    "    adaptive_huffman_encode(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "710 ms ± 223 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "for filename, text in [texts[2]]:\n",
    "    adaptive_huffman_encode(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.3 s ± 156 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "for filename, text in compressed_texts:\n",
    "    adaptive_huffman_decode(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "948 ms ± 283 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "for filename, text in [compressed_texts[2]]:\n",
    "    adaptive_huffman_decode(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "for filename, text in [compressed_texts[1]]:\n",
    "    adaptive_huffman_decode(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wnioski\n",
    "Współczynnik kompresji osiąga bardzo zbliżone wartości niezależnie od sposobu kopresji - widoczna różnica pojawia się tylko przy kompresji małych plików. Róznica ta jest głównie spowodowana dodatkowymi informacjami przechowanymi razem z tekstem (alfabet zajmuje mniej miejsca niż zapis całego kodowania, więc kodowanie dynamiczne osiąga lepszy współczynnik), których wielkość traci znaczenie przy długich tekstach.  \n",
    "Czas kompresji jest w algorytmie dynamicznym jest około 20x dłuższy niż przy algorytmie statycznym, więc biorąc pod uwagę niewielkie zmiany w wielkości plików wynikowych kodowanie algorytmem statycznym okazuje się ogólnie wydajniejsze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
